name: newspaper_scraper_periodic
on:
  schedule:
    - cron: "*/30 * * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: .
    steps:
      - name: Check out this repo
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Update repo
        run: apt update
      - name: Installed package list
        run: apt list --installed
      - name: Install necessary packages
        run: sudo apt install git libxml2-dev libxslt-dev python3-dev python3-lxml
      - name: Install all necessary python modules
        run: pip install -r requirements.txt
      - name: Expose GitHub secrets as individual environment variables
        env:
          SECRETS_CONTEXT: ${{ toJson(secrets) }}
        run: |
          secrets=$(echo "$SECRETS_CONTEXT" | jq -r 'to_entries[] | select(.key != "WG_CONFIG_FILE") | .key + "=" + .value')
          echo "$secrets" >> $GITHUB_ENV
      - name: Set up WireGuard Connection
        uses: niklaskeerl/easy-wireguard-action@v2
        with:
          WG_CONFIG_FILE: ${{ secrets.WG_CONFIG_FILE }}
      - name: Run the script
        run: python main.py
        working-directory: .
